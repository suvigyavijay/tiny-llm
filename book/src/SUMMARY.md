# LLM Serving in a Week

[Preface](./preface.md)
[Setting Up the Environment](./setup.md)

---

- [Week 1: From Matmul to Text](./week1-overview.md)
    - [Attention and Multi-Head Attention](./week1-01-attention.md)
    - [Positional Encodings and RoPE](./week1-02-positional-encodings.md)
    - [Grouped/Multi Query Attention](./week1-03-gqa.md)
    - [RMSNorm and MLP](./week1-04-rmsnorm-and-mlp.md)
    - [The Qwen2 Model](./week1-05-qwen2-model.md)
    - [Generating the Response](./week1-06-generate-response.md)
    - [Sampling and Preparing for Week 2](./week1-07-sampling-prepare.md)
- [Week 2: Tiny vLLM](./week2-overview.md)
    - [Key-Value Cache](./week2-01-kv-cache.md)
    - [Quantized Matmul - CPU](./week2-02-quantized-matmul-cpu.md)
    - [Quantized Matmul - GPU](./week2-03-quantized-matmul-gpu.md)
    - [Flash Attention - CPU](./week2-04-flash-attention-cpu.md)
    - [Flash Attention - GPU](./week2-05-flash-attention-gpu.md)
    - [Continuous Batching (2 Days)](./week2-06-prefill-and-batch.md)
- [Week 3: Serving]()

---

[Glossary Index](./glossary.md)
